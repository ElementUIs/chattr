---
title: "Interact with OpenAI GPT models"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{openai-gpt}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Intro

OpenAI's GPT models are possibly the most widely used LLM today. Typically, the
interaction with the models is via chatting with it inside the OpenAI's web
portal. They also offer an REST API endpoint that you can use to communicate
with their LLM's. `chattr` is able to send and recieve the correct API calls 
to make the "chatting" experience with the GPT models seamless.  

## Secret key

OpenAI requires a **secret key** to authenticate your user. It is required for 
any application non-OpenAI application, such as `chattr`, to have one in order 
to function. A key is a long alphanumeric sequence. The sequence is created in 
the OpenAI portal. To obtain your **secret key**, follow this link: 
[OpenAI API Keys](https://platform.openai.com/account/api-keys)

By default, `chattr` will look for the **secret key** inside the a Environment
Variable called `OPENAI_API_KEY`. Other packages that integrate with OpenAI use 
the same variable name.

Use `Sys.setenv()` to set the variable. The downside of using this method is
that the variable will only be available during the current R session:

``` r
Sys.setenv("OPENAI_API_KEY" = "####################")
```

A preferred method is to save the secret key to the `.Renviron` file. This way, 
there is no need to load the environment variable every time you start a new R
session. The `.Renviron` file is available in your home directory. Here is an 
example of the entry:

```         
OPENAI_API_KEY=####################
```

## Test connection 

Use the `chattr_test()` function to confirm that your connection works:

``` r
library(chattr)

chattr_test()
✔ Connection with OpenAI cofirmed
✔ Access to models confirmed
```

## Change the model

By default, `chattr` is setup to interact with GPT 3.5 (`gpt-3.5-turbo`). To
switch to the DaVinci model (`text-davinci-003`) run:

```{r}
library(chattr)

chattr_use("davinci")
```

To switch back to GPT 3.5, run:

```{r}
chattr_use("gpt35")
```

If you wish to switch to a model other than the two mentioned above, you will
first need to note which of the two OpenAI endpoints you will need to reach: 
`completions` or `chat/completions`. "gpt35" points to the `chat/completions` 
endpoint, and "davinci" to the `completions` endpoint.

For example, if you wish to switch to the Curie model, first run:

```{r}
chattr_use("davinci")
```

And then run:

```{r}
chattr_defaults(model = "text-curie-001")
```
If you are allowed to access GPT 4, and wish to use it via `chattr` then run:

```{r}
chattr_use("gpt35")
```

```{r}
chattr_defaults(model = "gpt-4")
```
To see the latest list which endpoint to use, go to : [Model Endpoint Compatability](https://platform.openai.com/docs/models/model-endpoint-compatibility)

## Data files and data frames

Because it is information about your environment and work space, by default 
`chattr` avoids sending any data files, and data frame information to OpenAI. 
Sending this information is convenient because it creates a shorthand for your
requests. If you wish to submit this information as part of your prompts, 
use `chattr_defaults()`, for example:

- `chattr_defaults(max_data_files = 10)`
- `chattr_defaults(max_data_frames = 10)`

These two commands will send 10 data frames, and 10 data files as part of your
prompt.  You can decide the number to limit this by. The more you send,
the larger your prompt.

If any of these is set to anything but 0, a warning will show up every time
you start the Shiny app.
