default:
  prompt: |
    {tc_base_prompt}
  provider: Open AI
  model: GPT 3.5 Turbo
  include_data_files: TRUE
  include_data_frames: TRUE
  include_doc_contents: FALSE
  include_history: TRUE
  system_msg: You are a helpful coding assistant
  model_arguments:
    temperature: 0.01
    max_tokens: 1000
    stream: TRUE
notebook:
  prompt: |
    {readLines(system.file("prompt/base.txt", package = "tidychat"))}
    For code output, use RMarkdown code chunks, set eval=FALSE for all chunks
    Include alt text code chunk option for all plots
chat:
  prompt: |
    {readLines(system.file("prompt/base.txt", package = "tidychat"))}
    For code output, use markdown code chunks
console:
  prompt: |
    {readLines(system.file("prompt/base.txt", package = "tidychat"))}
    For any line that is not code, prefix it with a: #
