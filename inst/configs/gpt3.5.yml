default:
  tidychat:
    default:
      prompt: |
        {tidychat_openai_gpt3_base()}
      provider: Open AI
      model: GPT 3.5 Turbo
      include_data_files: TRUE
      include_data_frames: TRUE
      include_doc_contents: FALSE
      include_history: TRUE
      system_msg: You are a helpful coding assistant
      model_arguments:
        temperature: 0.01
        max_tokens: 1000
        stream: TRUE
    notebook:
      prompt: |
        {tidychat:::tidychat_openai_gpt3_base()}
        For code output, use RMarkdown code chunks
        Include alt text code chunk option for all plots
    chat:
      prompt: |
        {tidychat:::tidychat_openai_gpt3_base()}
        For code output, use markdown code chunks
    console:
      prompt: |
        {tidychat:::tidychat_openai_gpt3_base()}
        For any line that is not code, prefix it with a: #
